# В топ Highload Cup на Perl

В конце августа Mail подогнал довольно интересный конкурс, озаглавленный как Highload Cup. Я подумал: "М-м-м, хайлоад! Надо поучаствовать"

Первоначально я бегло прочитал описание из которого выцепил следующее: REST API на 5 методов, 3 сущности и 2 связи между ними, и очень скромный, по меркам хайлоада RPS: 2000. Ещё и на 4 ядра. "Какой-же это хайлоад?" подумал я тогда. Ну и раз так, точно надо попробовать!

Вы можете прочитать [полное описание задания](https://highloadcup.ru/media/condition/howto.html), но нужно учесть, что это финальная версия, которая изменялась и улучшалась несколько раз.

Данные хорошо укладывались в реляционную модель (user <-> visit <-> location), поэтому первая мысль была такая: беру самую подходящую для хайлоада базу - Tarantool, ставлю перед ней асинхронный HTTP сервер на 4 воркера, подключаю к базе - профит! Для начала, чтоб реализовать апи и разобраться с взаимосвязями данных я решил взять только сервер, причём в режиме одного ядра и с данными в памяти.

На момент старта конкурса не было никаких тестовых данных - только описание API. Поэтому я писал тест по тому, как я его понимал, реализовывал метод, писал тест, реализовывал метод. В итоге за вечер я набросал работающее решение. Первоначальный набор модулей - AnyEvent::HTTP::Server, EV, JSON::XS, Time::Moment. Кстати отдельно про Time::Moment: вот этот код был написан в самом начале и не изменился до финала, хотя у подавляющего большинства участников очень часто были проблемы с вычислением дней рождений

```perl
our $NOW = Time::Moment->from_epoch($now);
...
        my $older = $NOW->minus_years( $prm->{fromAge} )->epoch;
        push @cond, "\$_->{user}{birth_date} <= $older";
...
        my $younger = $NOW->minus_years( $prm->{toAge} )->epoch;
        push @cond, "\$_->{user}{birth_date} > $younger";
...
```

В общем решение написано, локально вроде работает, надо бы запушить.

Вот тут и засада №1 - Docker. До этого мне не доводилось ни ставить докер, ни как либо использовать. Ну что-же, хороший повод начать. Гуглю, ставлю, и... BSOD! На маке (Black Screen of Death), а не то, что вы могли подумать. Это первый раз, когда я увидел BSOD, ну ок, раз начал, надо идти до конца. повторяю процесс, со второго раза завелось. Ладно, идём дальше. Проверяю докер дефолтным образом - вроде работает. надо теперь как-то запихнуть всё внутрь. К этому моменту в телеграмовском чате, который я стараюсь читать не пропуская пробегает сообщение о [baseimage контейнере](http://phusion.github.io/baseimage-docker/). Пробегаю по диагонали - кажется это то, что мне нужно. Пока я разбираюсь со сборкой, появляются первые тестовые данные с ответами. Отлично! Пишу по быстрому [тестер](https://github.com/Mons/hlcup/blob/2c96f064f931a79d75a6609e79ac98948ef2503d/tester.pl), прогоняю решение - 100% PASS.

## 15-16 августа

Собираю свой [первый контейнер](https://github.com/Mons/hlcup/blob/2c96f064f931a79d75a6609e79ac98948ef2503d/baseperl/Dockerfile), пушу его на сервер... 10 минут ожидания и... WAT?

Фаза обстрела # 1 (GET): Процент верных ответов 32.8052805280528
Фаза обстрела # 2 (POST): Процент верных ответов    100
Фаза обстрела # 3 (GET): Процент верных ответов 34.2941176470588

Иду, смотрю детали:
Получен ответ:
```json
{
  "city": "Роттерламск",
  "id": "125",
  "distance": 42,
  "country": "Палау",
  "place": "Двор"
}
```
Верный ответ:
```json
{
  "distance": 42,
  "city": "Роттерламск",
  "country": "Палау",
  "place": "Двор",
  "id": 125
}
```

Вот-же блин. Моя тестовая программа, равно как и сам сервер, используют JSON::XS. А тот смотрит на наличие SvPV флага на скаляре (иными словами - не строка ли это). А т.к. я использую id'шники, как ключи в хэше - они все становятся строками. Обвешиваю всё "костылями" `0+` для возврата, ещё немного тестов, обстрел, фиксы, обстрел... С 6й попытки у меня 100% PASS на тестирующей системе. Отлично, думаю. Запускаю рейтинговый! И, 119848.439812 штрафа! Как так? 1 фаза - ок, вторая - ок. 3я - 62%. Иду в графики и наблюдаю, что после 960 PRS что-то пошло не так. Самое сложное, что непонятно, что происходит внутри. На чём затык, т.к. нет графиков cpu/io. Делаю простой мониторинг (5387). К сожалению логи выдаются не целиком, а top/mid/bottom. В итоге у меня логи загрузки json и финальные строки лога, когда обстрел уже прекратился.

Анализируем ситуацию: Highload Cup оказался Latency Cup. Соответственно становится понятно, что о связках perl->tarantool можно забыть, ибо это минимум +1ms к каждому запросу и нужно брать данные из собственной памяти (особенно если учесть, что персистентность не требуется). Второй момент - в запросах не используется keep-alive, каждый запрос - новое соединение. Также начинает приходить осознание, что ядра то может и 4, но ядрышки слабенькие (как выяснил потом  Intel Xeon E312xx Sandy Bridge, 3999 bogomips). И в условиях логики, которую я привнёс в приложение от моих референсных 8kRPS на ядро для GET /hello-world остались в лучшем случае 1k.

# 17 августа

Становится понятно, что HTTP-Server из этого варианта надо убирать и делать что попроще ;) Пишется наколеночный http-server под только такие типы запросов, выполняется тюнинг сокета (SO_LINGER => 0, TCP_NODELAY => 1, TCP_QUICKACK => 1, TCP_FASTOPEN не поддерживается) (7086)

Выяснил, что sysctl не работает, всё можно делать только через setsockopt (хотя почему-то до конца не убирал вызовы sysctl ;)

Немного отлаживаю локально, исправляю мелкие баги в сервере, рейтинговый обстрел (7115) и 150.940976! При этом есть 36 неверных ответов в фазе POST, что означает +72 секунды штрафа. Т.е по хорошему можно уменьшить время до 80

# 18 августа

В голову приходит, что всё то логгирование, которое я делаю, может тупить. На всякий случай делаю под логгирование отдельный процесс, в который пересылаю через пайп. Заодно там-же телаю простенький системный мониторинг. Делаю преаллокацию ключей хэша на продовый объём. Раскручиваю циклы.

Нахожу багу с POST'ом без Content-Length. Это и были мои 36 ошибок.

А заодно придумываю как оптимизировать латенси при POST.

Что такое POST - это декодирование, валидация и обновление данных. В моей модели нет деревьев, все связки хранятся отсортированными списками (Для имеющегося набора данных это было приемлемо). Соответственно апдейт - это несколько циклов по удалению/вставке. Пока цикл работает - никакой запрос не может быть принят. А вот если в циклах делать небольшие паузы, то можно дать возможность событийному циклу принять соединение и обработать его. Так родился `aefor` (скоро на CPAN)

вместо цикла
```perl
for ( 0..$#$old ) {
    if ( $old->[$_]{visit}{id} == $vis->{id} ) {
        $ptr = splice @$old, $_,1, ();
        last;
    }
}
```
получался
```perl
aefor 0, $#$old, sub {
    if ( $old->[$_]{visit}{id} == $vis->{id} ) {
        $ptr = splice @$old, $_,1, ();
        last;
    }
}, sub {
    # end of loop
}
```

Сложно сказать, изменило-ли конкретно это что-то значительно, но однозначно этот код уже нашёл применение в проде - там циклы бывают на десятки тысяч элементов. Но в итоге все изменения дали итог (8914) - 112.419574 (и 2 ошибки в 3й фазе). Ошибки говорят о том, что где-то есть проблема в POST фазе. Обнаружил проблему в пограничном условии в aefor, заодно увеличил количество итераций с 10 до 50. Вспомнил опцию TCP_LINGER2, добавил и её. Обстрел - 81.809672, 100% и куча информации о состоянии процесса под нагрузкой. Там, к сожалению интересного ничего не нашёл.

## 20-21 августа

Времени нет, просто запускал рейтинговые. Получил 80.586385
(график)

## 22 августа

Работавшее топовое решение вдруг перестаёт работать.

```
id="989d8c47d0c8": Pull complete
id="e7fb81b6af20": Extracting
id="94b6b60b6f76": Download complete
...
Ошибка при выполнении docker-compose up...
Pulling client_8324 (stor.highloadcup.ru/travels/rabbit_climber:latest)...
```

Пробую более ранние - тоже не работают. В чате ещё что-то жалуется на подобное. Забиваю с мыслями: "починят".

## 23 августа

Не починили. Говорят про какие-то файлы в контейнере с неправильными uid, которые во что-то не могут смаппиться. Изучаю контейнер изнутри, нахожу эти файлы (от URI::XSEscape, uid 1326596177), добавляю очистку. Всё равно не работает. Решаю попробовать собрать контейнер с нуля, заодно на Centos 7 (как и базовая система).

Приходит понимание, что это не baseimage и нужно сделать свою "[демонизацию](https://github.com/Mons/hlcup/blob/master/centos/daemon.pl#L61-L147)" под несколько процессов. Заодно выясняю, что, оказывается, нормальный контейнер должен останавливаться по SIGINT (Ctrl+C), а не так, как это делал baseimage (хотя возможно я неправильно его готовил). В общем собираю, проверяю - локально всё работает. Пуш - та-же ошибка.

Раз такое дело и пока пушить некуда, решаю собрать гентушный контейнер (всё равно хотел). Навешиваю `-march=sandybridge`, ставлю stableperl (хэши чуточку быстрее). Тестирую демон от версии с centos. Локально всё работает. Пуш - та-же ошибка. Хотя нет, не та-же: к этому моменту смотрю, организаторы мне ответили: "нашли и поправили ошибку, спасибо!". У меня в консоли новая ошибка:
```
id="53af9fd773ea": Download complete
error: failed to register layer: ApplyLayer exit status 1 stdout: stderr: Container ID 1326596177 cannot be mapped to a host ID
```

## 24 августа

Иду к оргам, матерюсь, прошу объяснить что за фигня, в контейнере чисто - я удалил все левые файлы. Мне доходчиво объясняют, что скачиваются все слои докера и в каком-то из слоёв докера лежат эти файлы. До меня доходит, благодарю, немного исправляю [Dockerfile](https://github.com/Mons/hlcup/blob/51fe81871473072bee2f5414a239c018bf97e6b7/gentoo/Dockerfile#L41) - заработало (ключевая строчка - `rm -rf /root/.cpanm`)!

Решаю протестировать "нововведение": заменить хэши на массивы (данные лежат плотно, а массивы, если что, резиновые). А заодно и "нативный образ на Centos 7. Также добавляю собственную статистику изнутри (21353). Обстрел - 116.899637.
Тестирую то-же самое с Ubuntu - 111.580241. Планирую следующим запустить образ с Gentoo.

## 25 августа

Выходные пропускаю, а тем временем...

## 26 августа

>Друзья, мы стартанули с увеличенными данными и плотностью RPS обстрела.
Пример данных можно посмотреть [тут](https://github.com/sat2707/hlcupdocs/tree/master/data)
Именно такой объем данных и RPS будут в финале.

Данных в 10 раз больше, рпс в 5 раз.

## 27 августа

Читаю об изменениях. Заливаю в него тестовые данные. Понимаю, что не уложусь по RPS. Решаю сделать "[inmemory db](https://github.com/Mons/hlcup/tree/master/libs/Local-HLCup)": XS + std::map/std::multimap.
Во первых более компактное хранение. Во вторых возможность работать с древовидными структурами и избавиться от full-scan. В третьих возможность вынести фильтрующие циклы в слой на C. Заодно решил закостылить возврат JSON без копирований и лишних вызовов. Тестирую на полном объёме данных: 3.2 Gb RAM, 5600 RPS. Решаю посмотреть в рейтинговом прогоне. Для этого и всех последующих улучшений я использовал образ gentoo (хотя, кстати, так и не сравнил с ubuntu и centos в равных условиях).

260102.016396. Смотрю графики. Сломался на 4k RPS. Печально, локально даже больше было.

## 28-29 августа

Решаю заменить HTTP Parser с регэкспов/index'ов на HTTP::Parser::XS. Локально даёт 9800. и 100% прохождение. Понимаю, что мало, но отправляю на прогон (27008). Сломался на 7500RPS. А заодно и набрал 15109 неверных ответов на POST и в результате завалил ещё и 3ю фазу. Итог - 739491.365476.

Вечером глянул, нашёл баг в POST'е (27678), пофиксил, запушил. Попрофилировал. Нашёл, что urldecode съедает прилично времени. Сделал xs'ный urldecode. Ускорил эту часть в 5 раз.

Потом посмотрел на это всё... И решил, что с сетевым слоем в Perl особо не разгонишься и часа за 3 написал [http-сервер на XS](https://github.com/Mons/hlcup/tree/master/libs/Local-HTTPServer). Локальный бенч `GET /hello` - 60k RPS. Собрал решение, kокально потестил - работает. Запушил, запустил рейтинговый прогон и ушёл спать.

## 29 августа

340! И 100% PASS.

## 30 августа

В принципе результат очень неплохой 42 место в рейтинге. Выше перла нет ни одного скриптового язы... ЧТОА? на несколько строк выше "PHP" со скором в ~280. Решаю оптимизировать роутинг (тем более, думаю я, вряд-ли у кого-то из топа используется что-то неоптимизированное под задачу). Делаю роутинг прямо внутри http-сервера с коллбэками на перловые функции. Заодно учу "базу", возвращающую JSON, валидировать параметры и возвращать также и статус. Оптимизировал таким образом 4 GET метода, работу с вычислением возраста копировать было лениво - оставил в Perl слое вместе с валидацией с вычислением через Time::Moment. Локальный бенч - 30k RPS. Собрал, запушил, обстрелял.

243.770117. 42 место.

За это время "PHP" поднялся выше до значений около 220. Я стал сильно сомневаться в том, что это PHP ;)

Объявляют, что топ финалистов - это 50 топовых решений и что пушить можно до 20:00. Понимаю, что времени что-то переделывать и сильно улучшать нет (как-бы ещё есть работа), но в последний момент решаю затестить [send с флагами OOB/DONTROUTE](https://github.com/Mons/hlcup/blob/master/libs/Local-HTTPServer/HTTPServer.xs#L242). OOB не прошёл на одном и локальных тестов, его убрал и в 19:50 я пушу финальное решение. В 22:15 решение проходит тестовую проверку (в последний день очереди на тестирование были огромные). В 01:00 у меня должны открыться 2 последние попытки рейтингового обстрела. В 03:00 постановка в очередь на обстрел закрывается. В 01:00 запускаю первый обстрел, в 02:53 запускаю второй, проверяю рейтинг, обнаруживаю себя уже на 46 месте и с мыслями "до утра могу не остаться в 50" ухожу спать.

## 31 августа

Первым делом, отключив будильник, смотрю рейтинг. Смотрю с конца. 50..49..48..47.. - нет меня. Блин, вытеснили, думаю. Проматываю посмотреть кто там выше и обнаруживаю себя на строчке **25** с показателем **212.348724**. Ура, я в [топ 50](https://highloadcup.ru/media/ckeditor/2017/09/02/rating.html). PHP с 13го места, как выяснилось, превратился в тыкву, т.е. в C++ с epoll'ом.

На протяжении последующих дней решения многократно обстреливались и [кликнув на любое решение](https://highloadcup.ru/rating/round/2/), вы можете посмотреть на всё так, как на это смотрели участники: на графики, тайминги и прочее.

К сожалению организаторам не удалось побороть пики яндекс-танка и моему решению за 9 обстрелов не попалось ни одного обстрела без "пиков", поэтому лучшее время в финале 225.03622 и 37 место. Как показал анализ решений финалистов, после того, как решения были выложены, Perl оказался единственным скриптовым языком, вошедшим в Top 50.

В завершение могу сказать, что я сильно удивился отсутствию в топе Lua, Node.js и Python. В этих языках существует сильная культура написания модулей на C или ffi, а это давало хорошую возможность выйти в топ.

Огромное спасибо организаторам за создание этого конкурса!
Для меня итог следующий:
- разобрался с докером, с несколькими способоми его сборки и запуска
- изучил современные флаги TCP/IP сокетов (хоть и не довелось их применить в контейнере)
- Сделал библиотечку aefor, которая пойдёт на CPAN и в прод
- Научился использовать STL в связке с XS. В планах реализовать map/multimap на `SV *` (мне всегда не хватало ordered hash в Perl)
- Разобрался с сишным API picohttpparser
- Начал писать XS'ный HTTP сервер (лежало в планах уже 1.5 года)

Но не менее интересными были итоги раскрытия решений финалистов. У всех топовых финалистов был один и тот-же "хак" - запуск epoll в режиме busy-loop, т.е. `epoll(0)`. Как выяснилось, это позволяет снизить latency, что, как-раз и требовалось в этом конкурсе.

Посмотреть решения можно на гитхабе в виде [таблицы](https://github.com/proton/highloadcup17_solutions) или поискав по тегу [#highloadcup](https://github.com/search?q=topic%3Ahighloadcup&type=Repositories)

